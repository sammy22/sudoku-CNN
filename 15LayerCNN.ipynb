{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"15LayerCNN.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gejiNctPTZP4"},"source":["# All imports here\n","\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import *\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hobFcb6U0Tn"},"source":["# Helper method to Build Model\n","def buildModel():\n","\n","  model = Sequential()\n","\n","  # Layer 1\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', input_shape=(9,9,1)))\n","  \n","  # Layer 2\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  \n","  # Layer 3\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  \n","  # Layer 4\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","\n","  # Layer 5\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  model.add(BatchNormalization())\n","\n","  # Layer 6\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  \n","  # Layer 7\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  \n","  # Layer 8\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  model.add(BatchNormalization())\n","\n","  # Layer 9\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","\n","  # Layer 10\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  model.add(BatchNormalization())\n","\n","  # Layer 11\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  \n","  # Layer 12\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","\n","  # Layer 13\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","  model.add(BatchNormalization())\n","\n","  # Layer 14\n","  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\n","\n","  # # Layer 15\n","  model.add(Conv2D(512, kernel_size=(1,1), activation='relu', padding='same'))\n","\n","  # Flatten and Dense\n","  model.add(Flatten())\n","  model.add(Dense(81*9))\n","  model.add(Reshape((-1, 9)))\n","  model.add(Activation('softmax'))\n","\n","  adam = Adam(learning_rate=0.001)\n","  model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFjpRWaeWgV5"},"source":["# Initialize the model\n","model3 = buildModel()\n","model3.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUyuOusVW0Ru"},"source":["# Path for the data set\n","one_million_path = \"/content/drive/MyDrive/Sudoku_Solver/data/1Million.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"26kkVt-lXlW7"},"source":["# Read in data in pandas\n","one_million_dataset = pd.read_csv(one_million_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPIaPU9wXW17"},"source":["# Helper method Split the data set into Train and Test Splits\n","def train_test_split_data(df, test_ratio=0.2): \n","\n","    questions = []\n","    solutions = []\n","\n","    # Process questions and solutions\n","    for idx, row in df.iterrows():\n","      # Pre process question\n","      question = row['quizzes']\n","      question = (np.array(list(map(int,list(question)))).reshape((9,9,1))/9) - 0.5\n","      # print(question.shape)\n","      questions.append(question)\n","\n","      # Pre process solutions\n","      solution = row['solutions']\n","      solution = (np.array(list(map(int,list(solution)))).reshape(81, 1)) - 1\n","      # print(\"Solution\", solution.shape)\n","      solutions.append(solution)\n","\n","    x_train, x_test, y_train, y_test = train_test_split(np.array(questions), np.array(solutions), test_size=test_ratio, random_state=42)\n","\n","    del(questions)\n","    del(solutions)\n","    \n","    return x_train, x_test,y_train, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mQDTaCJXc38"},"source":["X_train, x_test, Y_train, y_test = train_test_split_data(one_million_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOksU8CacqC1"},"source":["print(len(X_train), len(Y_train), len(x_test), len(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UdsqEsasXdam"},"source":["# Fit the model on train data\n","model3.fit(X_train, Y_train, batch_size=512, epochs=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNGQAu_DfIXe"},"source":["# Save the model\n","model3.save(\"/content/drive/MyDrive/Sudoku_Solver/data/model_15Layer_1M.h5\")"],"execution_count":null,"outputs":[]}]}