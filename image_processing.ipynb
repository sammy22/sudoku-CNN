{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_processing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvN6L/n0xmiNbhLndICK0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammy22/sudoku-CNN/blob/main/image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcu23QCit2YQ"
      },
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XekHJ5XZufsF"
      },
      "source": [
        "clone the repo to load the images and model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck0u7q0020Qk",
        "outputId": "331047a4-8c84-4ddb-c335-891ad92257fe"
      },
      "source": [
        "!git clone https://github.com/sammy22/sudoku-CNN.git"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sudoku-CNN'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 40 (delta 11), reused 25 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOstq8J2ujJP"
      },
      "source": [
        "Read and display the sudoku image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khUxE9acuLJv"
      },
      "source": [
        "# img = cv2.imread('./sudoku-CNN/images/img_15.png')\n",
        "img = cv2.imread('./sudoku-CNN/images/img_10.jpeg')\n",
        "# cv2_imshow(img)"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJzrcv59u2w6"
      },
      "source": [
        "Convert image to grayscale and apply thresholding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVV8aew_uneI"
      },
      "source": [
        "width,height = 450,450 # to have all image of same size\n",
        "img = cv2.resize(img, (width, height))  \n",
        "imgBlank = np.zeros((height, width, 3), np.uint8)  # for testing\n",
        "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
        "imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1) \n",
        "imgThreshold = cv2.adaptiveThreshold(imgBlur, 255, 1, 1, 11, 2)  \n",
        "# cv2_imshow(imgThreshold)"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcVWBLjiu8PP"
      },
      "source": [
        "Some images of sudoku have gaps between images. To fix this we use morphological transformation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHRG335owbf0"
      },
      "source": [
        "# kernelSize = (3,3)\n",
        "# kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernelSize)\n",
        "# imgThreshold = cv2.morphologyEx(imgThreshold, cv2.MORPH_GRADIENT, kernel)\n",
        "# cv2_imshow(imgThreshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gJrzK20xIqI"
      },
      "source": [
        "Finding the biggest contour in an image. as thats the boundary of sudoku. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVnhGW_wu8XN"
      },
      "source": [
        "imgContours = img.copy() \n",
        "contours, hierarchy = cv2.findContours(imgThreshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # FIND ALL CONTOURS\n",
        "cv2.drawContours(imgContours, contours, -1, (0, 255, 0), 3) # DRAW ALL DETECTED CONTOURS\n",
        "# cv2_imshow(imgContours)\n",
        "\n",
        "biggest,max_area = np.array([]),0\n",
        "for i in contours:\n",
        "    area = cv2.contourArea(i)    \n",
        "    if area > 50:\n",
        "        approx = cv2.approxPolyDP(i, 0.02 * cv2.arcLength(i, True), True)\n",
        "        if area > max_area and len(approx) == 4:\n",
        "            biggest,max_area = approx,area\n",
        "#print(biggest)"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wD7V6qc2xOR"
      },
      "source": [
        "split image into 81 images, one image for every cell "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXRIxmAyX3D"
      },
      "source": [
        "def reorder(myPoints):\n",
        "    myPoints = myPoints.reshape((4, 2))\n",
        "    myPointsNew = np.zeros((4, 1, 2), dtype=np.int32)\n",
        "    add = myPoints.sum(1) # add x and y coordinates\n",
        "    myPointsNew[0],myPointsNew[3] = myPoints[np.argmin(add)],myPoints[np.argmax(add)] #topleft and bottom right \n",
        "    diff = np.diff(myPoints, axis=1)\n",
        "    myPointsNew[1],myPointsNew[2] =myPoints[np.argmin(diff)],myPoints[np.argmax(diff)] #topright and bottom left\n",
        "    return myPointsNew\n",
        "\n",
        "imgBigContour = img.copy() \n",
        "if biggest.size != 0:\n",
        "    biggest = reorder(biggest)\n",
        "    cv2.drawContours(imgBigContour, biggest, -1, (0, 0, 255), 25) \n",
        "    # cv2_imshow(imgBigContour)\n",
        "    pts1 = np.float32(biggest) \n",
        "    pts2 = np.float32([[0, 0],[width, 0], [0, height],[width, height]]) \n",
        "    matrix = cv2.getPerspectiveTransform(pts1, pts2) # GER\n",
        "    imgWarpColored = cv2.warpPerspective(img, matrix, (width, height))\n",
        "    imgDetectedDigits = imgBlank.copy()\n",
        "    imgWarpColored = cv2.cvtColor(imgWarpColored,cv2.COLOR_BGR2GRAY)\n",
        "    # cv2_imshow(imgWarpColored)\n",
        "    boxes=[]\n",
        "    for rows in np.vsplit(imgWarpColored,9):\n",
        "        for box in np.hsplit(rows,9):\n",
        "            boxes.append(box)\n",
        "    #cv2_imshow(boxes[55])"
      ],
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E6tLtnZQaMD"
      },
      "source": [
        "Load model trained on different epochs. Whichever works best for the image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mdenIKy36EH"
      },
      "source": [
        "model = tf.keras.models.load_model('./sudoku-CNN/mnist_10.h5')\n",
        "# model = tf.keras.models.load_model('./sudoku-CNN/mnist_15.h5') \n",
        "# model = tf.keras.models.load_model('./sudoku-CNN/mnist_30.h5')"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPw-illZQidh"
      },
      "source": [
        "Predict each cell and generate the sudoku as list "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNMfMyT95GVy"
      },
      "source": [
        "predictions = []\n",
        "for image in boxes:\n",
        "    im = np.asarray(image)\n",
        "    im = im[5:im.shape[0] - 5, 5:im.shape[1]-5]\n",
        "    im = cv2.resize(im, (28, 28))\n",
        "    im = cv2.bitwise_not(im)     \n",
        "    if np.sum(img >200)==0:\n",
        "      predictions.append(0)\n",
        "      continue\n",
        "    im = im.reshape(1, 28, 28, 1)/255\n",
        "    predictions.append(np.argmax(model.predict(im),axis=1)[0])\n",
        "\n",
        "sudoku_array=[[predictions[9*i+j] for j in range(9)] for i in range(9)]"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUDbW6cMQTRx"
      },
      "source": [
        "# print(np.array(sudoku_array))\n",
        "# cv2_imshow(img)"
      ],
      "execution_count": 355,
      "outputs": []
    }
  ]
}